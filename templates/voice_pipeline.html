<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Pipeline - Day 9</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: white;
        }
        
        .navbar {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 15px 30px;
            margin-bottom: 30px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        
        .navbar h1 {
            margin: 0;
            font-size: 1.5rem;
        }
        
        .nav-links {
            display: flex;
            gap: 20px;
        }
        
        .nav-links a {
            color: white;
            text-decoration: none;
            padding: 10px 20px;
            border-radius: 25px;
            background: rgba(255, 255, 255, 0.2);
            transition: all 0.3s ease;
        }
        
        .nav-links a:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: translateY(-2px);
        }
        
        .nav-links a.active {
            background: rgba(255, 255, 255, 0.4);
            font-weight: bold;
        }
        
        .container {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 40px;
            margin: 20px 0;
            text-align: center;
        }
        
        h1 {
            color: #fff;
            margin-bottom: 30px;
            font-size: 2.5rem;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        
        .day-badge {
            background: linear-gradient(45deg, #ff6b6b, #feca57);
            padding: 10px 20px;
            border-radius: 25px;
            font-weight: bold;
            font-size: 1.1rem;
            margin-bottom: 30px;
            display: inline-block;
        }
        
        .pipeline-info {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 15px;
            padding: 20px;
            margin: 20px 0;
            text-align: left;
        }
        
        .pipeline-steps {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }
        
        .step {
            background: rgba(255, 255, 255, 0.1);
            padding: 15px;
            border-radius: 10px;
            text-align: center;
            font-size: 0.9rem;
        }
        
        .step-number {
            background: #ff6b6b;
            color: white;
            width: 30px;
            height: 30px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 0 auto 10px;
            font-weight: bold;
        }
        
        .recording-container {
            margin: 30px 0;
        }
        
        .record-button {
            background: linear-gradient(45deg, #ff6b6b, #ff8e53);
            color: white;
            border: none;
            padding: 15px 30px;
            border-radius: 50px;
            font-size: 1.2rem;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 10px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.2);
        }
        
        .record-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(0,0,0,0.3);
        }
        
        .record-button:disabled {
            background: #666;
            cursor: not-allowed;
            transform: none;
        }
        
        .stop-button {
            background: linear-gradient(45deg, #e74c3c, #c0392b);
        }
        
        .recording-indicator {
            display: none;
            color: #ff6b6b;
            font-size: 1.1rem;
            margin: 10px 0;
            animation: pulse 1.5s infinite;
        }
        
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
        
        .loading {
            display: none;
            text-align: center;
            margin: 20px 0;
        }
        
        .spinner {
            border: 4px solid rgba(255, 255, 255, 0.3);
            border-top: 4px solid #fff;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
            margin: 0 auto 10px;
        }
        
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        
        .result {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 15px;
            padding: 20px;
            margin: 20px 0;
            text-align: left;
            display: none;
        }
        
        .result h3 {
            margin-top: 0;
            color: #feca57;
        }
        
        .result-section {
            margin: 15px 0;
            padding: 15px;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 10px;
        }
        
        .result-section h4 {
            margin: 0 0 10px 0;
            color: #ff6b6b;
        }
        
        .pipeline-progress {
            display: none;
            margin: 20px 0;
        }
        
        .progress-step {
            background: rgba(255, 255, 255, 0.1);
            padding: 10px 15px;
            margin: 5px 0;
            border-radius: 10px;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .progress-step.completed {
            background: rgba(76, 175, 80, 0.3);
        }
        
        .progress-step.processing {
            background: rgba(255, 193, 7, 0.3);
            animation: pulse 1.5s infinite;
        }
        
        audio {
            width: 100%;
            margin: 15px 0;
            border-radius: 10px;
        }
        
        .error {
            background: rgba(244, 67, 54, 0.2);
            border: 1px solid rgba(244, 67, 54, 0.5);
            color: #ffcdd2;
            padding: 15px;
            border-radius: 10px;
            margin: 20px 0;
            display: none;
        }
        
        @media (max-width: 768px) {
            .navbar {
                flex-direction: column;
                gap: 20px;
            }
            
            .nav-links {
                flex-wrap: wrap;
                justify-content: center;
            }
            
            h1 {
                font-size: 2rem;
            }
            
            .pipeline-steps {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <nav class="navbar">
        <h1>üé§ Voice Agents</h1>
        <div class="nav-links">
            <a href="/">üè† Home</a>
            <a href="/tts">üîä TTS Generator</a>
            <a href="/echo">üéôÔ∏è Echo Bot</a>
            <a href="/voice-pipeline" class="active">ü§ñ Voice Pipeline</a>
            <a href="/conversational-agent">üß† Conversational Agent</a>
            <a href="/conversational-agent">üí¨ Conversational AI</a>
        </div>
    </nav>
    
    <div class="container">
        <div class="day-badge">Day 9: Full Non-Streaming Pipeline</div>
        <h1>ü§ñ Voice AI Pipeline</h1>
        
        <div class="pipeline-info">
            <h3>üéØ Complete Voice-to-Voice AI Pipeline</h3>
            <p>Speak to the AI and get an intelligent voice response! This combines all technologies:</p>
            
            <div class="pipeline-steps">
                <div class="step">
                    <div class="step-number">1</div>
                    <strong>Record Audio</strong><br>
                    Capture your voice
                </div>
                <div class="step">
                    <div class="step-number">2</div>
                    <strong>Transcribe</strong><br>
                    Convert speech to text
                </div>
                <div class="step">
                    <div class="step-number">3</div>
                    <strong>AI Processing</strong><br>
                    Generate intelligent response
                </div>
                <div class="step">
                    <div class="step-number">4</div>
                    <strong>Voice Synthesis</strong><br>
                    Convert response to speech
                </div>
            </div>
        </div>
        
        <div class="recording-container">
            <button id="recordButton" class="record-button">üé§ Start Recording</button>
            <button id="stopButton" class="record-button stop-button" style="display: none;">‚èπÔ∏è Stop Recording</button>
            <div id="recordingIndicator" class="recording-indicator">üî¥ Recording... Speak now!</div>
        </div>
        
        <div id="loading" class="loading">
            <div class="spinner"></div>
            <p>Processing your voice through the AI pipeline...</p>
        </div>
        
        <div id="pipelineProgress" class="pipeline-progress">
            <h3>Pipeline Progress:</h3>
            <div id="step1" class="progress-step">
                <span>üé§</span>
                <span>Audio uploaded and saved</span>
            </div>
            <div id="step2" class="progress-step">
                <span>üìù</span>
                <span>Audio transcribed with AssemblyAI</span>
            </div>
            <div id="step3" class="progress-step">
                <span>üß†</span>
                <span>Text processed with Google Gemini</span>
            </div>
            <div id="step4" class="progress-step">
                <span>üîä</span>
                <span>Response converted to speech with Murf AI</span>
            </div>
        </div>
        
        <div id="error" class="error"></div>
        
        <div id="result" class="result">
            <h3>üéâ Pipeline Complete!</h3>
            
            <div class="result-section">
                <h4>üìù What you said:</h4>
                <p id="transcribedText"></p>
            </div>
            
            <div class="result-section">
                <h4>üß† AI Response:</h4>
                <p id="llmResponse"></p>
            </div>
            
            <div class="result-section">
                <h4>üîä Listen to AI Response:</h4>
                <audio id="responseAudio" controls></audio>
            </div>
        </div>
    </div>
    
    <script>
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        
        const recordButton = document.getElementById('recordButton');
        const stopButton = document.getElementById('stopButton');
        const recordingIndicator = document.getElementById('recordingIndicator');
        const loading = document.getElementById('loading');
        const pipelineProgress = document.getElementById('pipelineProgress');
        const result = document.getElementById('result');
        const error = document.getElementById('error');
        
        recordButton.addEventListener('click', startRecording);
        stopButton.addEventListener('click', stopRecording);
        
        async function startRecording() {
            try {
                // Reset UI
                result.style.display = 'none';
                error.style.display = 'none';
                pipelineProgress.style.display = 'none';
                
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                // Try different audio formats for better compatibility with AssemblyAI
                let options = {};
                
                // Prioritize formats that work better with transcription services
                if (MediaRecorder.isTypeSupported('audio/wav; codecs=pcm')) {
                    options = { mimeType: 'audio/wav; codecs=pcm' };
                } else if (MediaRecorder.isTypeSupported('audio/wav')) {
                    options = { mimeType: 'audio/wav' };
                } else if (MediaRecorder.isTypeSupported('audio/webm; codecs=opus')) {
                    options = { mimeType: 'audio/webm; codecs=opus' };
                } else if (MediaRecorder.isTypeSupported('audio/mp4; codecs=mp4a.40.2')) {
                    options = { mimeType: 'audio/mp4; codecs=mp4a.40.2' };
                } else if (MediaRecorder.isTypeSupported('audio/ogg; codecs=opus')) {
                    options = { mimeType: 'audio/ogg; codecs=opus' };
                } else {
                    // Use default format
                    options = {};
                }
                
                console.log('Attempting to use audio format:', options.mimeType || 'default');
                
                mediaRecorder = new MediaRecorder(stream, options);
                audioChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = () => {
                    // Use the actual MIME type from the recorder or fallback
                    const actualMimeType = mediaRecorder.mimeType || options.mimeType || 'audio/webm';
                    console.log('Recording completed with actual MIME type:', actualMimeType);
                    
                    // Create blob with proper MIME type
                    const audioBlob = new Blob(audioChunks, { type: actualMimeType });
                    console.log('Audio blob size:', audioBlob.size, 'bytes');
                    console.log('Audio blob type:', audioBlob.type);
                    
                    if (audioBlob.size === 0) {
                        showError('Recording failed - no audio data captured');
                        resetUI();
                        return;
                    }
                    
                    processAudio(audioBlob, actualMimeType);
                };
                
                mediaRecorder.start();
                isRecording = true;
                
                // Update UI
                recordButton.style.display = 'none';
                stopButton.style.display = 'inline-block';
                recordingIndicator.style.display = 'block';
                
            } catch (err) {
                showError('Error accessing microphone: ' + err.message);
            }
        }
        
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                
                // Stop all audio tracks
                const tracks = mediaRecorder.stream.getTracks();
                tracks.forEach(track => track.stop());
                
                // Update UI
                recordButton.style.display = 'inline-block';
                stopButton.style.display = 'none';
                recordingIndicator.style.display = 'none';
                loading.style.display = 'block';
                pipelineProgress.style.display = 'block';
            }
        }
        
        async function processAudio(audioBlob, mimeType) {
            try {
                // Reset progress steps
                const steps = document.querySelectorAll('.progress-step');
                steps.forEach(step => {
                    step.classList.remove('completed', 'processing');
                });
                
                // Show step 1 as processing
                document.getElementById('step1').classList.add('processing');
                
                // Create form data
                const formData = new FormData();
                
                // Check if audio blob is valid
                if (audioBlob.size < 1000) { // Less than 1KB
                    throw new Error('Audio recording is too short or empty. Please try recording for at least 1-2 seconds.');
                }
                
                // Use appropriate extension based on MIME type
                let filename = 'recording.webm';
                if (audioBlob.type.includes('wav')) {
                    filename = 'recording.wav';
                } else if (audioBlob.type.includes('ogg')) {
                    filename = 'recording.ogg';
                } else if (audioBlob.type.includes('mp4')) {
                    filename = 'recording.m4a';
                }
                
                console.log('Uploading audio file:', filename, 'Size:', audioBlob.size, 'Type:', audioBlob.type);
                formData.append('audio_file', audioBlob, filename);
                
                // Send to pipeline endpoint
                const response = await fetch('/llm/query-audio', {
                    method: 'POST',
                    body: formData
                });
                
                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.detail || 'Pipeline failed');
                }
                
                const data = await response.json();
                
                // Update progress with completed steps
                if (data.pipeline_steps) {
                    data.pipeline_steps.forEach((step, index) => {
                        setTimeout(() => {
                            const stepElement = document.getElementById(`step${index + 1}`);
                            stepElement.classList.remove('processing');
                            stepElement.classList.add('completed');
                            
                            if (index < 3) {
                                const nextStep = document.getElementById(`step${index + 2}`);
                                if (nextStep) nextStep.classList.add('processing');
                            }
                        }, index * 1000);
                    });
                }
                
                // Show results after animation
                setTimeout(() => {
                    loading.style.display = 'none';
                    displayResults(data);
                }, 4000);
                
            } catch (err) {
                loading.style.display = 'none';
                pipelineProgress.style.display = 'none';
                showError('Pipeline error: ' + err.message);
            }
        }
        
        function displayResults(data) {
            document.getElementById('transcribedText').textContent = data.transcribed_text;
            document.getElementById('llmResponse').textContent = data.llm_response;
            
            // Set up audio player
            const audio = document.getElementById('responseAudio');
            
            // Remove any existing demo button
            const existingButton = audio.parentNode.querySelector('.demo-button');
            if (existingButton) {
                existingButton.remove();
            }
            
            // Check if it's a demo mode (data URL or demo indication)
            if (data.audio_url.startsWith('data:') || data.voice.includes('Demo')) {
                // Use browser's speech synthesis for demo mode
                if ('speechSynthesis' in window) {
                    // Hide the audio element
                    audio.style.display = 'none';
                    
                    // Add a demo button instead
                    const demoButton = document.createElement('button');
                    demoButton.textContent = 'üîä Play Demo Response (Browser TTS)';
                    demoButton.className = 'record-button demo-button';
                    demoButton.style.marginTop = '10px';
                    demoButton.onclick = () => {
                        // Stop any ongoing speech
                        speechSynthesis.cancel();
                        
                        const utterance = new SpeechSynthesisUtterance(data.llm_response);
                        utterance.rate = 0.9;
                        utterance.pitch = 1;
                        utterance.volume = 1;
                        
                        utterance.onstart = () => {
                            demoButton.textContent = 'üîä Playing...';
                            demoButton.disabled = true;
                        };
                        
                        utterance.onend = () => {
                            demoButton.textContent = 'üîä Play Demo Response (Browser TTS)';
                            demoButton.disabled = false;
                        };
                        
                        utterance.onerror = (event) => {
                            console.error('Speech synthesis error:', event);
                            demoButton.textContent = 'üîä Play Demo Response (Browser TTS)';
                            demoButton.disabled = false;
                        };
                        
                        speechSynthesis.speak(utterance);
                    };
                    
                    audio.parentNode.appendChild(demoButton);
                } else {
                    audio.style.display = 'none';
                    const demoText = document.createElement('p');
                    demoText.textContent = 'Demo mode: Speech synthesis not available in this browser.';
                    demoText.style.color = '#feca57';
                    demoText.className = 'demo-button';
                    audio.parentNode.appendChild(demoText);
                }
            } else {
                // Use real Murf AI audio
                audio.src = data.audio_url;
                audio.style.display = 'block';
                
                // Log audio URL for debugging
                console.log('Playing Murf AI audio:', data.audio_url);
            }
            
            result.style.display = 'block';
        }
        
        function resetUI() {
            recordButton.style.display = 'inline-block';
            stopButton.style.display = 'none';
            recordingIndicator.style.display = 'none';
            loading.style.display = 'none';
            pipelineProgress.style.display = 'none';
        }
        
        function showError(message) {
            error.textContent = message;
            error.style.display = 'block';
            recordButton.style.display = 'inline-block';
            stopButton.style.display = 'none';
            recordingIndicator.style.display = 'none';
        }
    </script>
</body>
</html>
